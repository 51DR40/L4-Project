{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9b2a56-9edb-44b7-a501-6a8cafda7ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install rich accelerate gradio transformers numba datasets peft bitsandbytes torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd701d19-a043-4bd5-ae33-8d28f17bb2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "import datasets\n",
    "import re\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fe5604-2bd7-4597-8e89-85ed7c6bcfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-6.7b-instruct\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/deepseek-coder-6.7b-instruct\", trust_remote_code=True, torch_dtype=torch.bfloat16)\n",
    "\n",
    "# Wrap the model with DataParallel\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "# Move the model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e801e-7d10-477d-88e4-d863cc4a4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset('RayBernard/leetcode')#Leetcode dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4853a1-6e98-4445-86b9-3384847122d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b080c6-a223-48a1-9bbc-d947042f20e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [f\"Instruction: {inst}\\nInput: {inp}\" for inst, inp in zip(examples[\"instruction\"], examples[\"input\"])]\n",
    "    outputs = []\n",
    "    for output in examples[\"output\"]:\n",
    "        # Extract Python code from the output\n",
    "        code_blocks = re.findall(r\"```python(.*?)```\", output, re.DOTALL)\n",
    "        code = \"\\n\".join(code_blocks)\n",
    "        outputs.append(code)\n",
    "    \n",
    "    max_length = 485  # Set the maximum sequence length\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "    labels = tokenizer(outputs, truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c98d74-a0a2-4c50-9893-f3e3d7867953",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aa8f7b-51d9-4f9f-918c-96e53490ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "train_dataset = train_dataset.train_test_split(test_size=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc09e4-a2bc-4417-83e0-39f639391561",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043e8371-4d4d-444f-9dac-c33c5e5636bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = torch.tensor([item['input_ids'] for item in batch])\n",
    "    attention_mask = torch.tensor([item['attention_mask'] for item in batch])\n",
    "    labels = torch.tensor([item['labels'] for item in batch])\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset[\"train\"], batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(train_dataset[\"test\"], batch_size=16, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c0b44a-8112-4c9a-bc76-a91d03f535ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of training steps\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in train_dataloader:\n",
    "        inputs = {key: value.to(device) for key, value in batch.items() if key != \"labels\"}\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        progress_bar.update(1)\n",
    "    \n",
    "    train_loss /= len(train_dataloader)\n",
    "    progress_bar.set_description(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
